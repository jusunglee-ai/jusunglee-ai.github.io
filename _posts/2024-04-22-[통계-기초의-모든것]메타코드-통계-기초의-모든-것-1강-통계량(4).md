---
layout: single
title: 메타코드 통계 기초의 모든 것 1강_통계량(4)
category: Mathmatics
tag: [메타코드 , 메타코드m , metacode , metacodem , Probability and Statistics]
toc: true
math_use: true

---

이번에도 통계 용어 및 공식에 대해 정리를 해보도록 하겠습니다.

해당 강의는 메타코드 기업에서 후원을 받아 수강한 뒤 해당 강의에 대해 수강한 뒤 제가 공부하여 정리하여 여러분들에게 제공해드리는 것 입니다.

왜도(Skewness)

---

<p align="center"><img src="https://github.com/jusunglee-ai/jusunglee-ai.github.io/assets/125032849/2f7f478e-8416-4ba3-8634-0cc779b3b60d" width="70%" height="70%"></p>

먼저 왜도 입니다.
왜도(Skewness)는 분포의 비대칭도를 나타내는데요.

분포의 비대칭도의 정도에 따라 Positive, Negative로 나눌 수 있습니다.

그리고 비대칭도가 0인 즉 대칭인 분포도는 Symmetrical Distribution이라고 표현 합니다.

그럼 Positive와 Negative의 차이점을 한번 보도록 합시다.

우리가 보통 원점 0을 기준으로 왼쪽은 음수 오른쪽은 양수라고 일반적으로 생각하죠.

Positive Skew의 경우 오른쪽으로 꼬리가 길게 분포되어 있고, Negative Skew의 경우 왼쪽으로 꼬리가 길게 분포 되어 있습니다.

이런 특징을 보고 구별을 할 수 있습니다.

또한 skewness가 0일 때, 중앙값, 최빈값이 0이 됩니다.

그리고 Skewness의 종류에 따라 그래프의 특징이 있는데요.

만약 Positive skew일 경우 (mode<median<mean)

Negative skew일 경우(mode>median>mean)이렇게 크기가 정의가 됩니다.

첨도(Kurtosis)

---

<p align="center"><img src="https://github.com/jusunglee-ai/jusunglee-ai.github.io/assets/125032849/a2493200-9847-472d-a9fa-e87f75f3a962" width="60%" height="60%"></p>

다음은 첨도인데 첨도는 그래프가 얼마나 뾰족한지에 대한 뾰족한 정도를 나타냅니다.

보통 표준정규분포의 첨도는 3입니다.

이거는 이정도만 알아도 되니 이정도만 알고 넘기겠습니다.

상관(Correlation)

---

<p align="center"><img src="https://github.com/jusunglee-ai/jusunglee-ai.github.io/assets/125032849/3c0b9a36-3b1c-46b8-8299-73c4191e8d4a" width="60%" height="60%"></p>

상관은 확률변수 즉 Random variable들 간의 서로 관계가 있을 때 상관관계가 있다고 합니다.

대표적인 예시로 x=y함수죠. x가 커지는 만큼 y도 커지는 상관 관계가 있기 때문입니다.

그리고 이러한 상관 관계가 선형적 관련성이 있다고 합니다.

공분산(Covariance)

---

<p align="center"><img src="https://github.com/jusunglee-ai/jusunglee-ai.github.io/assets/125032849/b9d2a2b8-c77b-4fea-8225-e0d505b1fefe" width="60%" height="60%"></p>

공분산은 확률 변수 x와 y의 관련성을 표현하기 위해 사용합니다.

이는 표본 공분산을 구하기 때문에 n-1로 나누는거고 S를 쓰는 겁니다.

근데 먼가 저 식 익숙하지 않나요? 

바로 우리가 앞에서 배운 분산식과 똑같습니다.

???:먼 개소리함? 분산식은 $ (x_i-\bar{x})^2$이잖음

- 네 맞습니다. 우리는 x와 y두 확률 변수의 분산을 구하기 때문에 $ (x_i-\bar{x}) (y_i-\bar{y})$를 쓰는 겁니다. 확률 변수가 2개이기 때문에 $(x_i-\bar{x})$를 2번 하는게 아니라 $x_i$와 $y_i$를 넣어 2번 하는겁니다.

상관계수(Correlation Coefficient)

---

<p align="center"><img src="https://github.com/jusunglee-ai/jusunglee-ai.github.io/assets/125032849/1867faa9-8b73-4183-9dc3-c10ee3beaf4f" width="60%" height="60%"></p>

마지막으로는 상관계수입니다.

상관계수란 확률 변수 X와 Y의 연관이 서로 얼마나 있는지 알기 위한 수 입니다.

상관계수의 공식은 매우 어려워 보이지만 굉장히 쉽게 표현할 수 있습니다.

이 수식을 좀 뜯어 보면 쉬운데요

위 수식은 $\frac{S_x_y}{S_xS_y}$와 같습니다.

이 수식은 표본 공분산을 x의 표준 편차와 y의 표준편차로 나누어 준 것 과 똑같습니다.

상관계수의 핵심적인 특징

- 절댓값 1에 가까울수록 연관성의 강도가 높다는 것을 알 수 있다는 것.
- 상관계수가 0에 가까워질수록 연광성의 강도가 낮음.
- 같은 데이터를 단위가 다르게 측정하였을 때도 상관계수는 같음 즉 단위가 없음.
- 이 상관계수는 피어슨 correlation ship이라는 것.
