---
layout: single
title: Incetpion v1 paper review(논문 리뷰)
category: Mathmatics
tag: [Deep-learning,Machine-Learing,Paper-review,Inception]
toc: true
math_use: true

---

이번에는 GoogleNet으로 유명한 **Going deeper with convolutions 논문을 리뷰하도록 하겠습니다.**

Going deeper with convolutions 논문은 가장 초기 Inception 논문으로써, version 1을 담당하고 있습니다.

그럼 Inception 논문 리뷰 해보도록 하겠습니다.

## Abstract

---

해당 모델은 ILSVRC14에 출전한 neural network이며, 모델 이름은 Inception모델입니다.

해당 모델의 특징은 컴퓨터 리소싱 활용도가 높으며, 계산 비용은 일정하게 유지하지만 neural network의 깊이나 넓이는 더 증가 시키는 디자인을 하고 있다는 겁니다.

즉, 모델의 깊이나 크기는 더 크고 깊게 만들면서, 계산하는데 필요한 파라미터나 계산량은 일정하게 유지하거나 줄이는게 목적으로 만들어진 모델이라고 저는 생각이 드네요.

## Introduction

---

Introduction에서는 지난 3년간 딥 러닝 학습 방법과 다양한 모델이 발전하면서 여러가지 네트워크가 나왔으며 이는 이 분야의 큰 발전에 기여 했다고 하네요 또한 ILSVRC에서 다루는 데이터 셋인 ImageNet데이터 셋트 외에는 사용하지 않았다고 하는데 우리가 이 논문에서 봐야할 중요할 부분이 아니니 넘기도록 하겠습니다.

중요한 부분 중 하나인 ILSVRC 2014에 제출한 GoogleNet은 2년전에 나왔던 AlexNet보다 12배나 적은 parameter를 사용하였는데도 더 좋은 성능(정확한)결과를 얻을 수 있었다고 하네요.

또한 이때 당시에는 임베디드 컴퓨팅과 모바일에 관심이 많아서 되게 메모리 사용이나, 알고리즘 최적화 등 최대한 연산량을 적게하며, 가볍고 빠른 기법들에 대해 관심이 많았다고 합니다.

그래서 이러한 배경을 통해 효율적인 계산을 하는 컴퓨터 비전용 deep convolution neural network Inception이 탄생했다고 저자는 설명합니다.

아무래도 이러한 배경 때문에 Inception이 나오지 않았나 싶네요.

Introduction은 이 Inception Network가 나오게 된 배경 그리고 Network를 만들 때 focus를 어디에 뒀는지 말해주는 내용 같습니다.

Related work

---

LeNet-5를 기점으로 해서 CNN은 마지막 레이어에 항상 Fully-connected layer가 1개 2개씩 붙는게 일반적인 CNN 모델의 형상이 되었습니다.

이 형태는 image-classification에서 좋은 성능을 가지게 되어, 널리 퍼지게 되었으며, 또한 Cifar-100,10 혹은 imageNet같은 대규모 데이터 셋 같은 큰 대규모 네트워크에서는 이러한 Fully-connected layer를 마지막에 연결하는게 큰 성능을 낸다는 것을 실험결과를 통해 나왔기 때문에 이게 일반적으로 많이 쓰이게 되었다고 합니다.

실제로 Image Classification 대회에 제출 된 논문들의 architecture를 보면 죄다 이런식으로 설계가 되어 있습니다.

또한 overfitting 문제를 해결하기 위해 Dropout을 사용 하였다고 합니다.

두 번째로는 1x1 convolution filter를 사용하여 채널을 축소시켜, bottleneck 현상을 제거 할 수 있으며, 또한 네트워크의  크기를 줄일 수 있다는  입니다.

이를 통해서 성능 저하 없이 네트워크의 깊이를 깊게 할 수 있다고 합니다.

그리고 이 부분이 Inception block의 뿌리가 되는 아이디어라고 하네요.

그 다음 Related work로는 R-CNN입니다.

이때 당시에 R-CNN은 object detection에서 가장 좋은 접근 방식이였다고 합니다.

이 부분은 R-CNN에 대해 제가 잘 모르기도 하며, Inception논문에서 핵심이 아니라고 생각하기에 따로 R-CNN부분을 만들어 다루도록 하겠습니다.

Motivation and HIgh Level Considerations

---

네트워크의 성능을 높이는 가장 좋은 방법은 바로 모델을 깊게 만들어 더 크게 만드는거라고 합니다.

여기서 네트워크를 깊게 한다는 것은 Label의 수와 width모두 포함이라고 합니다.

특히 이러한 방법은 ImageNet과 같이 클래스가 굉장히 많고 양이 많은 많은 데이터를 학습시킬 때 가장 안전한 훈련 방법이라고 합니다.

이 세상의 모든 방법은 양날의 검이 있듯이, 이 방법에도 양날의 검이 있습니다. 위와 같이 장점이 있으면, 단점도 있죠.

이 단점은 두 개가 있습니다.

네트워크의 크기가 커질수록 parameter수도 많아지고 훈련 세트의 label이 한정되어 있다면 overfitting 현상이 발생하기도 쉽다고 합니다.

또한 고품질의 데이터 셋을 만들어 사용한다면, 상당히 까다롭고 비용이 많이 비쌉니다.

두 번째 단점

이렇게 균일한 크기로 증가되는 네트워크의 또 다른 단점은 바로 컴퓨팅 리소스 사용이 극적으로 증가한다는 것 입니다.

이 말은 기존의 CNN과 같이 직렬 연결처럼 1자로 깊게 연결 시킨다면은 네트워크의 layer가 굉장히 많아지며, 컴퓨팅 리소스도 굉장히 많이 필요하게 되기 때문이라고 조심스럽게 생각해봅니다.

이 논문에 예시를 들어보겠습니다.

만약 2개의 Convolution Network가 연결되어 있는 경우 필터 수가 균일하게 증가하면 계산량이 2배 증가하게 된다는 거죠.

또한 추가된 capacity가(가중치가 0에 가까운 경우) 많은 계산량이 낭비가 됩니다.

이는 이 네트워크의 목적과 굉장히 어긋나는 부분이죠.

이 네트워크는 모델의 구조를 깊게 만들어 성능을 향상 시키고 싶어 하지만, 네트워크가 깊어진다면 계산량이 굉장히 많이 늘어나기 때문에 이러한 부분을 최적화 하는 것이 목적이기 때문입니다.

그렇기에 이러한 목적을 이루기 위해 고안한 방법이 바로

fully connected layer를 sparsely connected layer로 바꾸는 것 입니다.

![Untitled](Inception%20paper%20review(%E1%84%82%E1%85%A9%E1%86%AB%E1%84%86%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B5%E1%84%87%E1%85%B2)%20c161a5b8fb344b7cb3b4f31943a3449d/Untitled.png)

좌 sparse layer, 우 Dense layer

그리고 이렇게 layer를 바꾼 결과 Inception architecture가 네트워크로서 localization 파악, object detection 분야에서 특히 유용하다는 것을 확인했다고 저자가 설명합니다.

근데 저자는 이게 컴퓨터 비전 분야 발전에는 큰 동기부여가 되었지만, 실제로 이게 정말로 확실한 성능 향상 방법론인지에 대해서는 좀 더 여러가지 실험과 확인이 필요하다고 하네요.

## Architecture Details

---

드디어 나왔습니다.

Inception Network의 핵심 Inception Block에 대해 소개해보도록 하겠습니다.

![Untitled](Inception%20paper%20review(%E1%84%82%E1%85%A9%E1%86%AB%E1%84%86%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B5%E1%84%87%E1%85%B2)%20c161a5b8fb344b7cb3b4f31943a3449d/Untitled%201.png)

위의 사진은 Inception Module 사진입니다.

기존의 CNN의 모델과 너무나도 다르지 않나요?

바로 병렬연결처럼 되어 있다는 것 입니다.

보통은 직렬연결과 같이 하나의 convolution layer에서 feature를 추출한 뒤 output으로 추출한 feature를 다음 convolution layer에 전달하여 input으로 사용함으로서 다시 convolution 연산을 진행하는 구조였습니다만.

이 방법은 하나의 input을 여러 개의 convolution layer에 전달하면서, 연산을 진행한 뒤 여러 개의 convolution layer의 아웃풋을 Filter concatenation에 전달하는 구조 입니다.

그럼 왜 이 구조를 선택하였으며, 이 구조의 장점이 무엇인지 알아 보도록 하겠습니다.

먼저 optimal local sparse structure를 쉽게 찾는 방법을 구할 수 있는 방법으로 이러한 방법을 선택하였다고 하는데요.

이 방법은 dense가 높은 component들로 근사한 뒤 커버가 가능한 방법을 찾는 것을 base로 한다고 합니다.

뭐 이런 저런 너무 어렵고 처음 들어본 말들로 논문이 이루어져 있어 너무나도 어렵게 느껴지실 것 같습니다.

그러니 주저리 주저리 말하는거 넘어가고 여러분에게 1분 요약 같이 핵심을 짚어 드리자면, 바로 위에서 나왔던 fully-connected layer에서 sparse한 네트워크로 구조를 바꾼다는 것 입니다.

그리고 위와 같은 구조의 장점은 바로 적은 연산량 혹은 제한된 연산량을 용하는데도 불구하고, 똑같은 input을 여러 종류의 convolution layer에 통과 시킴으로써 다양한 feature를 얻을 수 있다는 겁니다.

또한 이것은 제 개인적인 의견이긴 합니다만,

이 논문을 읽으며 들었던 생각은 다양한 필터를 통해 다양한 feature를 얻을 수 있기에 성능 향상이 이루어 질 수 있으며, 기존 직렬 연결처럼 연결된 기존의 CNN은 convolution layer를 지나면 지날수록 vanishing gradient가 발생 할 수 있습니다.

또한 기존 CNN구조의 작동 방식은 convolution layer를 통과한 output을 input으로 받는 구조입니다.

그렇기 때문에 이미 추출된 feature map을 다시 input으로 사용하기 때문에 똑같이 1x1, 3x3, 5x5 , 3x3 max pooling layer를 통과한다고 가정하였을 때 Inception module과 기존 convolution은 큰 차이가 발생할 것이라고 생각이 됩니다. 왜냐하면 이미 convolution layer를 통과하면서 추출된 feature map을 다시 convolution layer에 넣어서 feature map을 추출하기 때문이죠 . 이런 부분에서 다양한 feature map을 얻을 수 없다고 생각이 듭니다.

그리고 무엇보다도 이런 방식으로 네트워크가 너무 깊게 이어지게 된다면 feature가 오히려 손실이 될 수 있다고 생각이 들기 때문에 성능향상으로 이어지는게 아닌가 싶네요.

다음은 b 모델을 보도록하겠습니다.

b는 신기하죠 1x1 convoltuion 이후에 3x3, 5x5를 적용하니까요.

이 부분을 하는 이유는 바로 채널 축소입니다.

왜 채널을 축소하냐면 이미지 데이터가 크면 클수록, 모델의 구조가 깊고 복잡하면 복잡할 수록 더욱 더 많은 연산량을 요구하기 때문에 이런 문제점을 해결하고자 나온 방안입니다.

또한 ReLu함수를 더 많이 적용함으로써, 비선형성을 더 많이 획득을 할 수 있다는 장점이 있죠.

이유는 아래의 사진을 참고해주시면 좋을 것 같습니다.

![Untitled](Inception%20paper%20review(%E1%84%82%E1%85%A9%E1%86%AB%E1%84%86%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B5%E1%84%87%E1%85%B2)%20c161a5b8fb344b7cb3b4f31943a3449d/Untitled%202.png)

[출처:[https://warm-uk.tistory.com/44](https://warm-uk.tistory.com/44)]

마지막으로 Auxillary classifier

이걸 사용하는 이유는 Vanishing gradient 방지 목적입니다.

모델의 중간 중간에 이 분류기를 넣음으로서, 해당 분류기에서 계산 되어진 큰 값의 backpropagation결과 값이 중간마다 더해지는 것이기 때문에 전체적인 모델의 기울기가 작아지는 문제는 해결 할 수 있다고 하네요.

근데 이것도 엄청나게 극적인 효과는 없다고 합니다..

마지막으로 architecture 구조를 보여드리고 마치겠습니다.

왜냐하면 그 뒤에는 실험결과 값이니 다루지 않도록 하겠습니다..

또한 학습을 하며 구현을 하고 싶으신 분들은 제 github에 가면 있으니 확인해 보시길 바라겠습니다.

![Untitled](Inception%20paper%20review(%E1%84%82%E1%85%A9%E1%86%AB%E1%84%86%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B5%E1%84%87%E1%85%B2)%20c161a5b8fb344b7cb3b4f31943a3449d/Untitled%203.png)
