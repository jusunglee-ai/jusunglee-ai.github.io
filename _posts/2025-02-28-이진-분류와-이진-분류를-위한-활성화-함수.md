---
layout: single
title: 이진 분류와 이진 분류를 위한 활성화 함수(activation function)
category: Mathmatics
tag: [Probability and Statistics, 인공지능 기초]
toc: true
math_use: true

---
# 이진 분류와 이진 분류를 위한 활성화 함수

회귀 문제에서는 분류 문제를 많이 다룹니다.

그리고 이러한 분류 문제는 대표적으로 이진 분류(binary classification)과 다중 분류(multi-class classification)가 있습니다.

먼저 그럼 이진 분류(binary classification)에 대해서 알아 보도록 하겠습니다.

## 이진 분류(binary classification)이란?

---

단 두 가지의 class로 즉, 두 가지 종류로 데이터들을 분류하는 것 입니다.

대표적인 예시로 많이 드는 것이 스팸 메일과 일반 메일 혹은 객체 이미지에 결함이 존재 하냐 안하냐와 같이 0과 1로만 구분이 가능한 데이터 형태 입니다.

또한 이렇게 분류할 수도 있습니다. 데이터가 있는데 해당 데이터는 고양이와 강아지로만 구성이 되어있는 데이터 입니다.

그리고 이 데이터를 고양이는 0 강아지는 1로 구분하여 구분 할 수도 있습니다.

이러한 분류를 binary classification이라고 칭합니다.

그럼 한번 예시를 보며, binary classification을 위한 모델은 어떻게 설계를 하고 어떤 과정이 이루어지는지 한번 알아보도록 합시다.

# 이진 분류를 해결하는 과정 및 모델 설계 예시 과정

---

우리에게 주어진 데이터와 해결해야 하는 문제는 다음과 같습니다.

여러 사람들의 키와 몸무게를 데이터로 입력을 받아 해당 인물이 체중 감량이 필요한지, 혹은 체중 감량이 불 필요 한지에 대한 분류 문제를 해결 해보도록 하겠습니다.

그리고 해당 예제를 좀 더 시각화 하기 위해 혁편하임님의 Easy 딥러닝 책을 참고하여 사용하였습니다. 

### Step 1. 데이터 수집

---

우리는 다음과 같은 그래프를 사용하여 이진 분류를 수행을 해볼 예정입니다.

![image.png](https://github.com/user-attachments/assets/b2782296-d6b0-4141-9705-79051e14a0ed)

여기서 점들은 서로 다른 사람들이며,  파랑색 점은 체중 감량이 필요한 사람(1번 클래스) 빨간색 점은 체중 감량이 필요 없는 사람(0번 클래스)입니다.

인공지능의 특징은 다양한 케이스의 데이터가 많아지면 많아질수록 더욱 다양한 데이터가 들어 오더라도 해당 데이터를 이용하여 문제를 풀 수 있다는 것 입니다.

이러한 방식은 우리가 수능 공부를 할 때 정해진 문제만 풀어보는 것이 아니라 같은 범위 혹은 개념의 내용이더라도 그 개념을 응용한 다양한 문제를 풀어보는 방식과 굉장히 유사합니다. 

그리고 우리는 이러한 이진 분류를 해결하기 위해서 체중 감량이 필요한 사람과 체중 감량이 필요 없는 사람을 구분하는 구분 선(boundary decision)을 그리는 것이 목적이 됩니다.

이 구분 선을 이용하여서 새로운 케이스의 데이터가 들어오더라도 문제를 풀 수 있고 판단을 할 수 있게 하기 위함이지요.

### step 2. 모델 설계

---

![image.png](https://github.com/user-attachments/assets/3d2f626f-f3ca-4dd1-86ca-39f90cecea1b)

위의 그래프를 통해 알 수 있는 것은 키와 몸무게라는 데이터를 2차 평면에 나타내었으며, x축은 키 y축은 몸무게로 설정한 것을 알 수 있습니다.

그리고 우리는 키와 몸무게에 대해서 가중치(중요도)를 부여 할 예정 입니다.

이 가중치의 경우 키는 a라는 가중치,  몸무게는 b라는 가중치를 부여 할 것 입니다.

그리고 이렇게 키와 몸무게에 대해 각각의 가중치를 곱해준 뒤 이를 서로 더한 값에 추가적인 bias(편향 ‘c’로 표현)을 추가해줌으로써,  최종적인 한 사람의 데이터에 대한 가중치 합 값이 나왔습니다.

우리는 이 값을 활성화 함수 (Activation Function)에 넣어주는 작업을 수행할 것입니다.

그리고 우리는 여기서 히든 레이어 없이 Unit step Function을 활용한 신경망 모델을 사용하여 모델을 설계하도록 할 것 입니다.

여기서 Unit step function이란 우리가 맨 처음에 데이터를 받아 이를 각각 가중치에 곱한 뒤 합한 값에 bias를 낸 최종 값이 양수냐 음수냐에 따라서 0과 1을 출력하는 활성화 함수 입니다.

이를 수식으로 표현하면, ax+by+c값이 0보다 큰 양수면 1 해당 값이 0보다 작은 음수면 0을 출력하는 함수 입니다.

그리고 이 부등식을 y에 대해서 정리를 하게 된다면, 아래의 수식과 같습니다.

$y> -\frac{a}{b}x-\frac{c}{b} \\ y=-\frac{a}{b}x-\frac{c}{b}$


이 y에 대한 직선을 기준으로 이 직선보다 위에 있는 점들은 모두 1로 아래에 있는 점들은 0으로 구분하는 구분 선(boundary decision)이 되게 됩니다.

### step.3

---

![image.png](https://github.com/user-attachments/assets/52d7f5e8-e756-41b1-be85-b265ee2e0c9e)

다음은 모델을 학습하는 과정에 대해서 알아보도록 합시다.

우리는 활성화 함수를 통해서 우리가 입력한 데이터가 1로 분류 할지 0으로 분류할 지 구분 할 수 있습니다.

그리고 모델이 학습하는 것은 바로 이러한 분류 경계선(boundary decision)을 학습하는 것이며, 이 분류 경계선을 결정 짓는 인자(parameter)를 학습하는 것이 목적이라고 할 수 있습니다.

그리고 이러한 인자들은 가중치(weight)와 편향(bias)가 해당이 됩니다.

쉽게 표현하자면, 우리가 과일을 받았습니다.

근데 그 과일은 사과 배 둘 중 하나인 과일인데, 이 과일을 구분하기 위한 결정적인 부분을 알아내는 것을 모델이 학습 한다고 생각하시면 좀 더 편할 것 같습니다.

    

### step4. 모델테스트

---

![image.png](https://github.com/user-attachments/assets/5cf5713a-2b18-4e45-9c2b-e117515bf375)

다음은 모델이 정확하게 학습을 하고 학습한 데이터가 아닌 다른 케이스의 어떤 데이터가 오더라도 이러한 이진 분류 문제를 해결 할 수 있는지 모델을 평가하는 과정에 해당 합니다.

위의 그래프는 3D그래프로써, 입력 데이터와 출력 값에 대한 관계를 나타내주는 그래프 입니다.

해당 그래프의 경우, 입력과 출력의 관계가 비 선형적이라는 것 입니다.(직선으로 회귀가 되지 않으며 표현이 되지 않기 때문임)

그리고 이러한 결과 값이 나오게 된 이유는 활성화 함수가 바로 비선형 함수이기 때문입니다.  

해당 y=-ax/b-c/b라는 축을 기준으로 정확하게 입력에 따라 출력이 구분이 되지만, 이 부분에 있어서, 이를 구분하는 축이 선형인 것이지 출력을 선형으로 표현할 수 없기 때문입니다.

그리고 우리는 이 경계선을 기준으로 모델의 입력과 출력이 제대로 구분이 되는지 확인하여 테스트를 할 수 있습니다 

![image.png](https://github.com/user-attachments/assets/2f58c984-4457-4e14-a1b6-3d4f0fb9af69)

다음은 unit step function에대해 알아보도록 합시다.

해당 함수는 출력의 값이 0과 1 단 두 개만 나오는함수 입니다.

해당 함수는 x값이 0 미만은 출력 값이 0 0초과는 1이 나오는 함수이며, 이러한 함수가 왜 unit step function이라고 불리는지에 대해 알아 보도록합시다.

해당 함수를 2차원 그래프에 그리게 된다면, 해당 함수는 계단 형식의 그림으로 나오며 , 기본 단위인 0과 1로 나오기 때문에 unit step function이라는 이름이 붙여지게 되었습니다.

그래서 이 함수의 경우 너무 극단적 입니다. 0과 1로만 구분하고 이를 0과 1로만 결과 값으로만 내기 때문이죠.

그래서 이를 보완하기 위해 비슷한 함수인 sigmoid 함수 입니다.

해당 그래프에서 보게 된다면 둘 다 굉장히 비슷해 보일 겁니다.

그 이유는 다음과 같이 설명이 될 수 있는데요.

왜냐하면 두 함수 모두 0을 기준으로 y값이 변화가 되기 때문입니다.

약간 unit step function을 곡선으로 부드럽게 표현한 것이 sigmoid 함수라고 할 수 있습니다.

왜 그럼sigmoid 함수가 unit step function의 단점인 극단적으로 결과를 표현하는 부분을 보완해주는 함수일까요?

sigmoid함수는 곡선으로 부드럽게 표현된 함수이기 때문에, 전 구간을 그래디언트 기반(경사도 혹은 기울기 기반의 최적화 기법을 사용할 수 있습니다.)

두 번째로는 출력 값이 0과 1사이의 다양한 값이기 때문에 이를 해당 값이  정답일 확률로도 표현을 할 수도 있다는 점 입니다.

왜냐하면 boundary decision을 이용해서 0과 1로 단 두 개의 이진 분류를 했지만, 이 y의 값이 높을 수록 경계선을 기준으로 정답일 확률이 높은 것이고 0에 가까울 수록 정답에 멀어지기 때문에 확률로도표현을 할 수 있습니다.

이후 포스팅에서는 이러한 이진 분류를 위한 loss 함수에 대해서 알아보도록 하겠습니다.
